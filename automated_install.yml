---
- name: 'Beginning Kubernetes Cluster build'
  hosts: localhost
  gather_facts: false
  become: false
  connection: local

# Need two more prompts for Certificate ARNs
  vars_prompt:
    - name: region_name
      prompt: 'Enter the AWS region you will be building in (for instance: us-east-1)'
      private: false
    # - name: _server_cert_arn
    #   prompt: 'Enter the ARN of the kubernetes server cert'
    #   private: false
    # - name: _client_cert_arn
    #   prompt: 'Enter the ARN of the kubernetes client cert'
    #   private: false
    # - name: _account_num
    #   prompt: 'Enter your AWS account number'
    #   private: false


  vars_files:
    - common_vars.yml

  pre_tasks:
    - name: Check ssh key status
      stat:
        path: ~/.ssh/KubernetesKeyPair.pem
      register: _st

    - name: 'Check that ssh key is setup properly'
      ansible.builtin.assert:
        that:
          - _st.stat.exists
          - _st.stat.mode == '0400'
        fail_msg: 'SSH key is not setup properly.  Please run `make sshkey` and ensure permissions are 0400'

    - name: 'Retrieve AMI info of Ubuntu 24.04 image'
      ansible.builtin.shell:
        cmd: "aws ec2 describe-images --region {{ region_name }} --filters 'Name=name,Values=ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-20250610'"
      changed_when: false
      register: _ami_results

    - name: 'Format AMI output'
      ansible.builtin.set_fact:
        _ami_results_formatted: "{{ _ami_results.stdout | trim }}"
    
    - name: 'Get the AMI ID of the Image'
      ansible.builtin.set_fact:
        ami_id: "{{ _ami_results_formatted | json_query(_query) }}"
      vars:
        _query: "Images[].ImageId | [0]"

    - ansible.builtin.stat:
        path: "/var/tmp/.baseclusterinstall"
      register: _p

    - ansible.builtin.pause:
        prompt: "It appears the base Kubernetes cluster build has already run.  Do you wish to rerun? (Y/N)"
      when: _p.stat.exists == true
      register: rerun_input

    - ansible.builtin.set_fact:
        _rerun_input: "{{ rerun_input.user_input | lower }}"
      when: _p.stat.exists == true

    - ansible.builtin.set_fact:
        _rerun_input: 'y'
      when: _p.stat.exists == false

  # tasks:
  #   - name: 'Include CDK tasks'
  #     ansible.builtin.include_tasks: 'include_tasks/cdk.yml'
  #     when: "_rerun_input == 'y'"

  post_tasks:
    # - name: 'Pause 4 minutes to wait for EC2 instances to get created'
    #   ansible.builtin.pause:
    #     minutes: 4

    - name: 'Getting node information...'
      ansible.builtin.include_tasks: 'include_tasks/get_node_info.yml'
    
    - name: 'Add hosts to /etc/hosts'
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          {{ c1_cp1_public_ip }} c1-cp1 c1-cp1.example.com
          {{ c1_node1_public_ip }} c1-node1 c1-node1.example.com
          {{ c1_node2_public_ip }} c1-node2 c1-node2.example.com
          {{ c1_node3_public_ip }} c1-node3 c1-node3.example.com
      become: true

    - name: 'Add hosts to inventory'
      ansible.builtin.add_host:
        name: "{{ item.name }}"
        ansible_host: "{{ item.ip }}"
      loop:
        - { name: 'c1-cp1', ip: '{{ c1_cp1_public_ip }}' }
        - { name: 'c1-node1', ip: '{{ c1_node1_public_ip }}' }
        - { name: 'c1-node2', ip: '{{ c1_node2_public_ip }}' }
        - { name: 'c1-node3', ip: '{{ c1_node3_public_ip }}' }
    
- hosts: c1-cp1
  become: true
  gather_facts: true
  remote_user: ubuntu

  vars_files:
    - common_vars.yml

  environment:
    ANSIBLE_HOST_KEY_CHECKING: false

  pre_tasks:
    - ansible.builtin.stat:
        path: "/var/tmp/.baseclusterinstall"
      register: _file_exist

  tasks:
    - name: 'Update /etc/hosts'
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          {{ hostvars['localhost']['c1_cp1_private_ip'] }} c1-cp1.example.com c1-cp1
          {{ hostvars['localhost']['c1_node1_private_ip'] }} c1-node1.example.com c1-node1
          {{ hostvars['localhost']['c1_node2_private_ip'] }} c1-node2.example.com c1-node2
          {{ hostvars['localhost']['c1_node3_private_ip'] }} c1-node3.example.com c1-node3

  roles:
    - role: control-plane-node
      when: _file_exist.stat.exists == false

  vars:
    ansible_python_interpreter: '/usr/bin/python3'

  post_tasks:
    - name: 'Mark base cluster install complete' 
      ansible.builtin.copy:
       content: "complete"
       dest: "/var/tmp/.baseclusterinstall"
       force: true
      become: true

- name: 'Configure c1-node1'
  hosts: c1-node1
  gather_facts: true
  become: true
  remote_user: ubuntu

  vars_files:
    - common_vars.yml

  vars:
    ansible_python_interpreter: '/usr/bin/python3'

  pre_tasks:
    - ansible.builtin.stat:
        path: "/var/tmp/.wninstall"
      register: _file_exist

  tasks:
    - name: 'Update /etc/hosts'
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          {{ hostvars['localhost']['c1_cp1_private_ip'] }} c1-cp1.example.com c1-cp1
          {{ hostvars['localhost']['c1_node1_private_ip'] }} c1-node1.example.com c1-node1
          {{ hostvars['localhost']['c1_node2_private_ip'] }} c1-node2.example.com c1-node2
          {{ hostvars['localhost']['c1_node3_private_ip'] }} c1-node3.example.com c1-node3

  post_tasks:
    - name: 'Get the join command'
      ansible.builtin.pause:
        prompt: "Please paste in the join command: "
      register: _join_command
      delegate_to: localhost

    - name: 'Run the join-command to join the node to the cluster'
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          {{ _join_command.user_input }}
        executable: /bin/bash
      changed_when: false

    - ansible.builtin.copy:
        content: "complete"
        dest: "/var/tmp/.wninstall"
        force: true
      become: true

- name: 'Configure c1-node2'
  hosts: c1-node2
  gather_facts: true
  become: true
  remote_user: ubuntu

  vars_files:
    - common_vars.yml

  vars:
    ansible_python_interpreter: '/usr/bin/python3'

  pre_tasks:
    - ansible.builtin.stat:
        path: "/var/tmp/.wninstall"
      register: _file_exist

  tasks:
    - name: 'Update /etc/hosts'
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          {{ hostvars['localhost']['c1_cp1_private_ip'] }} c1-cp1.example.com c1-cp1
          {{ hostvars['localhost']['c1_node1_private_ip'] }} c1-node1.example.com c1-node1
          {{ hostvars['localhost']['c1_node2_private_ip'] }} c1-node2.example.com c1-node2
          {{ hostvars['localhost']['c1_node3_private_ip'] }} c1-node3.example.com c1-node3

  post_tasks:
    - name: 'Get the join command'
      ansible.builtin.pause:
        prompt: "Please paste in the join command: "
      register: _join_command
      delegate_to: localhost

    - name: 'Run the join-command to join the node to the cluster'
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          {{ _join_command.user_input }}
        executable: /bin/bash
      changed_when: false

    - ansible.builtin.copy:
        content: "complete"
        dest: "/var/tmp/.wninstall"
        force: true
      become: true

- name: 'Configure c1-node3'
  hosts: c1-node3
  gather_facts: true
  become: true
  remote_user: ubuntu

  vars_files:
    - common_vars.yml

  vars:
    ansible_python_interpreter: '/usr/bin/python3'

  pre_tasks:
    - ansible.builtin.stat:
        path: "/var/tmp/.wninstall"
      register: _file_exist

  tasks:
    - name: 'Update /etc/hosts'
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          {{ hostvars['localhost']['c1_cp1_private_ip'] }} c1-cp1.example.com c1-cp1
          {{ hostvars['localhost']['c1_node1_private_ip'] }} c1-node1.example.com c1-node1
          {{ hostvars['localhost']['c1_node2_private_ip'] }} c1-node2.example.com c1-node2
          {{ hostvars['localhost']['c1_node3_private_ip'] }} c1-node3.example.com c1-node3

  post_tasks:
    - name: 'Get the join command'
      ansible.builtin.pause:
        prompt: "Please paste in the join command: "
      register: _join_command
      delegate_to: localhost

    - name: 'Run the join-command to join the node to the cluster'
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          {{ _join_command.user_input }}
        executable: /bin/bash
      changed_when: false

    - ansible.builtin.copy:
        content: "complete"
        dest: "/var/tmp/.wninstall"
        force: true
      become: true

- name: 'Beginning installation of Kubernetes Dashboard'
  hosts: c1-cp1
  become: false
  gather_facts: true
  remote_user: ubuntu

  vars_files:
    - common_vars.yml

  vars:
    ansible_python_interpreter: '/usr/bin/python3'

  environment:
    ANSIBLE_HOST_KEY_CHECKING: false
  
  pre_tasks:
    - ansible.builtin.stat:
        path: "/var/tmp/.kd"
      register: _file_exist
  
  roles:
    - role: install-dashboard
      when: _file_exist.stat.exists == false
  
  post_tasks:
    - ansible.builtin.copy:
        content: "complete"
        dest: "/var/tmp/.kd"
        force: true
      become: true

#     - ansible.builtin.pause:
#         prompt: "Do you wish to install ElasticSearch into the Kubernetes cluster? (Y/N)"
#       register: _install_elastic

# - name: 'Beginning installation of ElasticSearch'
#   hosts: c1-cp1
#   become: false
#   gather_facts: true
#   remote_user: ubuntu

#   vars_files:
#     - common_vars.yml

#   vars:
#     ansible_python_interpreter: '/usr/bin/python3'

#   roles:
#     - role: install-elastic
#       when: _install_elastic.user_input | lower == 'y'

#   post_tasks:
#     - ansible.builtin.copy:
#         content: "complete"
#         dest: "/home/{{ svc_acct_name }}/.elasticinstall"
#         owner: "{{ svc_acct_name }}"
#         group: "{{ svc_acct_name }}"
#         force: true
#       when: _install_elastic.user_input | lower == 'y'

#     - ansible.builtin.pause:
#         prompt: "Do you wish to install the ArgoCD CI/CD Pipeline into the Kubernetes cluster? (Y/N)"
#       register: _install_cicd

# - name: 'Beginning installation of CI/CD Pipeline'
#   hosts: c1-cp1
#   become: false
#   gather_facts: true
#   remote_user: ubuntu

#   vars:
#     ansible_python_interpreter: '/usr/bin/python3'

#   vars_files:
#     - common_vars.yml

#   roles:
#     - role: cicd-pipeline
#       when: _install_cicd.user_input | lower == 'y'

#   post_tasks:
#     - ansible.builtin.copy:
#         content: "complete"
#         dest: "/home/{{ svc_acct_name }}/.cicdpipelineinstall"
#         owner: "{{ svc_acct_name }}"
#         group: "{{ svc_acct_name }}"
#         force: true
#       when: _install_cicd.user_input | lower == 'y'

#     - ansible.builtin.pause:
#         prompt: "Do you wish to install Rancher Server into the Kubernetes cluster? (Y/N)"
#       register: _install_rancher

# - name: 'Beginning installation of Rancher server'
#   hosts: c1-cp1
#   become: false
#   gather_facts: true
#   remote_user: ubuntu

#   vars:
#     ansible_python_interpreter: '/usr/bin/python3'

#   vars_files:
#     - common_vars.yml

#   roles:
#     - role: rancher-server
#       when: _install_rancher.user_input | lower == 'y'

#   post_tasks:
#     - ansible.builtin.copy:
#         content: "complete"
#         dest: "/home/{{ svc_acct_name }}/.rancherinstall"
#         owner: "{{ svc_acct_name }}"
#         group: "{{ svc_acct_name }}"
#         force: true
#       when: _install_rancher.user_input | lower == 'y'
...
